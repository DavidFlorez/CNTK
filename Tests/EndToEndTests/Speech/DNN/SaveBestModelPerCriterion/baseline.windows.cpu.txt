CPU info:
    CPU Model Name: Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz
    Hardware threads: 8
    Total Memory: 33439280 kB
-------------------------------------------------------------------
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 2 D:\source\CNTK_exp_private\0\x64\release\cntk.exe configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu DeviceId=-1 timestamping=true numCPUThreads=4 shareNodeValueMatrices=true saveBestModelPerCriterion=true stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:14:24

D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
Changed current directory to D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes on a single host (2 requested); we (0) are in (participating)
CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:14:24

D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
Changed current directory to D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes on a single host (2 requested); we (1) are in (participating)
MPI Rank 0: 02/03/2017 15:14:24: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr_speechTrain.logrank0
MPI Rank 0: CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:14:24
MPI Rank 0: 
MPI Rank 0: D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
MPI Rank 0: 02/03/2017 15:14:24: Using 4 CPU threads.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: ##############################################################################
MPI Rank 0: 02/03/2017 15:14:24: #                                                                            #
MPI Rank 0: 02/03/2017 15:14:24: # speechTrain command (train action)                                         #
MPI Rank 0: 02/03/2017 15:14:24: #                                                                            #
MPI Rank 0: 02/03/2017 15:14:24: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: 
MPI Rank 0: Creating virgin network.
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 0: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...........................................................................feature set 0: 83050 frames in 300 out of 300 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 300 utterances grouped into 1 chunks, av. chunk size: 300.0 utterances, 83050.0 frames
MPI Rank 0: 02/03/2017 15:14:24: 
MPI Rank 0: Model has 25 nodes. Using CPU.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 02/03/2017 15:14:24: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing: Out of 40 matrices, 21 are shared as 7, and 19 are not shared.
MPI Rank 0: 
MPI Rank 0: 	{ H1 : [512 x 1 x *]
MPI Rank 0: 	  W0*features : [512 x *]
MPI Rank 0: 	  W0*features : [512 x *] (gradient) }
MPI Rank 0: 	{ H2 : [512 x 1 x *]
MPI Rank 0: 	  W0 : [512 x 363] (gradient)
MPI Rank 0: 	  W0*features+B0 : [512 x 1 x *]
MPI Rank 0: 	  W0*features+B0 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  W1*H1 : [512 x 1 x *]
MPI Rank 0: 	  W1*H1 : [512 x 1 x *] (gradient) }
MPI Rank 0: 	{ HLast : [132 x 1 x *]
MPI Rank 0: 	  W2 : [132 x 512] (gradient) }
MPI Rank 0: 	{ B1 : [512 x 1] (gradient)
MPI Rank 0: 	  H2 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  HLast : [132 x 1 x *] (gradient) }
MPI Rank 0: 	{ W1 : [512 x 512] (gradient)
MPI Rank 0: 	  W1*H1+B1 : [512 x 1 x *] (gradient)
MPI Rank 0: 	  W2*H1 : [132 x 1 x *] (gradient) }
MPI Rank 0: 	{ W1*H1+B1 : [512 x 1 x *]
MPI Rank 0: 	  W2*H1 : [132 x 1 x *] }
MPI Rank 0: 	{ B0 : [512 x 1] (gradient)
MPI Rank 0: 	  H1 : [512 x 1 x *] (gradient) }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 02/03/2017 15:14:24: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 02/03/2017 15:14:24: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 0: 02/03/2017 15:14:24: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 0: 02/03/2017 15:14:24: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 0: 02/03/2017 15:14:24: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 0: 
MPI Rank 0: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:24: 	MeanOfFeatures = Mean()
MPI Rank 0: 02/03/2017 15:14:24: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 02/03/2017 15:14:24: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:27: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:28: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:28: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[   1-  10, 3.13%]: CrossEntropyWithSoftmax = 4.56731190 * 640; EvalClassificationError = 0.91718750 * 640; time = 0.1389s; samplesPerSecond = 4606.0
MPI Rank 0: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.31208878 * 640; EvalClassificationError = 0.92812500 * 640; time = 0.1313s; samplesPerSecond = 4874.4
MPI Rank 0: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.97319840 * 640; EvalClassificationError = 0.87343750 * 640; time = 0.1289s; samplesPerSecond = 4965.6
MPI Rank 0: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.73308124 * 640; EvalClassificationError = 0.84531250 * 640; time = 0.1327s; samplesPerSecond = 4822.9
MPI Rank 0: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  41-  50, 15.63%]: CrossEntropyWithSoftmax = 3.83238242 * 640; EvalClassificationError = 0.86406250 * 640; time = 0.1473s; samplesPerSecond = 4344.3
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.69914238 * 640; EvalClassificationError = 0.86093750 * 640; time = 0.1356s; samplesPerSecond = 4718.8
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.40238588 * 640; EvalClassificationError = 0.77812500 * 640; time = 0.1350s; samplesPerSecond = 4741.0
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.51740313 * 640; EvalClassificationError = 0.83750000 * 640; time = 0.1218s; samplesPerSecond = 5253.5
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  81-  90, 28.13%]: CrossEntropyWithSoftmax = 3.50059778 * 640; EvalClassificationError = 0.81250000 * 640; time = 0.1234s; samplesPerSecond = 5186.5
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39301549 * 640; EvalClassificationError = 0.80156250 * 640; time = 0.1245s; samplesPerSecond = 5140.3
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.48832144 * 640; EvalClassificationError = 0.82187500 * 640; time = 0.1274s; samplesPerSecond = 5023.2
MPI Rank 0: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.23814723 * 640; EvalClassificationError = 0.77031250 * 640; time = 0.1573s; samplesPerSecond = 4067.5
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 121- 130, 40.63%]: CrossEntropyWithSoftmax = 3.14333583 * 640; EvalClassificationError = 0.76093750 * 640; time = 0.1610s; samplesPerSecond = 3974.3
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.01547841 * 640; EvalClassificationError = 0.73906250 * 640; time = 0.1401s; samplesPerSecond = 4567.9
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91114805 * 640; EvalClassificationError = 0.71093750 * 640; time = 0.1324s; samplesPerSecond = 4834.3
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.06450741 * 640; EvalClassificationError = 0.74375000 * 640; time = 0.1462s; samplesPerSecond = 4378.9
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 161- 170, 53.13%]: CrossEntropyWithSoftmax = 2.77009796 * 640; EvalClassificationError = 0.69531250 * 640; time = 0.1436s; samplesPerSecond = 4455.4
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.67234909 * 640; EvalClassificationError = 0.64531250 * 640; time = 0.1456s; samplesPerSecond = 4395.9
MPI Rank 0: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.76324613 * 640; EvalClassificationError = 0.69843750 * 640; time = 0.1522s; samplesPerSecond = 4206.0
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.70050608 * 640; EvalClassificationError = 0.68125000 * 640; time = 0.1550s; samplesPerSecond = 4128.3
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 201- 210, 65.63%]: CrossEntropyWithSoftmax = 2.56019594 * 640; EvalClassificationError = 0.65312500 * 640; time = 0.1481s; samplesPerSecond = 4321.3
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.56796356 * 640; EvalClassificationError = 0.63906250 * 640; time = 0.1383s; samplesPerSecond = 4628.0
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.51054929 * 640; EvalClassificationError = 0.65000000 * 640; time = 0.1335s; samplesPerSecond = 4792.6
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.52174700 * 640; EvalClassificationError = 0.65468750 * 640; time = 0.1310s; samplesPerSecond = 4886.9
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 241- 250, 78.13%]: CrossEntropyWithSoftmax = 2.45943503 * 640; EvalClassificationError = 0.62812500 * 640; time = 0.1314s; samplesPerSecond = 4869.5
MPI Rank 0: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.36070476 * 640; EvalClassificationError = 0.62031250 * 640; time = 0.1441s; samplesPerSecond = 4442.1
MPI Rank 0: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.22167676 * 640; EvalClassificationError = 0.58125000 * 640; time = 0.1382s; samplesPerSecond = 4630.2
MPI Rank 0: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.48104909 * 640; EvalClassificationError = 0.66093750 * 640; time = 0.1419s; samplesPerSecond = 4510.8
MPI Rank 0: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 281- 290, 90.63%]: CrossEntropyWithSoftmax = 2.23253572 * 640; EvalClassificationError = 0.58906250 * 640; time = 0.1425s; samplesPerSecond = 4489.9
MPI Rank 0: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.22145425 * 640; EvalClassificationError = 0.60312500 * 640; time = 0.1679s; samplesPerSecond = 3811.0
MPI Rank 0: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.21771892 * 640; EvalClassificationError = 0.58125000 * 640; time = 0.1462s; samplesPerSecond = 4378.7
MPI Rank 0: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.19995645 * 640; EvalClassificationError = 0.59843750 * 640; time = 0.1346s; samplesPerSecond = 4755.7
MPI Rank 0: 02/03/2017 15:14:32: Finished Epoch[ 1 of 15]: [Training] CrossEntropyWithSoftmax = 3.00789787 * 20480; EvalClassificationError = 0.72641602 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=4.51191s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 02/03/2017 15:14:37: Final Results: Minibatch[1-1299]: CrossEntropyWithSoftmax = 2.20991696 * 83050; perplexity = 9.11495943; EvalClassificationError = 0.60792294 * 83050
MPI Rank 0: 02/03/2017 15:14:37: Finished Epoch[ 1 of 15]: [Validate] CrossEntropyWithSoftmax = 2.20991696 * 83050; EvalClassificationError = 0.60792294 * 83050
MPI Rank 0: 02/03/2017 15:14:37: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 2.209917 (Epoch 1); EvalClassificationError = 0.607923 (Epoch 1)
MPI Rank 0: 02/03/2017 15:14:37: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:37: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:37: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:14:37:  Epoch[ 2 of 15]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.09963072 * 2560; EvalClassificationError = 0.56132812 * 2560; time = 0.2778s; samplesPerSecond = 9214.7
MPI Rank 0: 02/03/2017 15:14:38:  Epoch[ 2 of 15]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.02412622 * 2560; EvalClassificationError = 0.55000000 * 2560; time = 0.3001s; samplesPerSecond = 8531.7
MPI Rank 0: 02/03/2017 15:14:38:  Epoch[ 2 of 15]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.00477550 * 2560; EvalClassificationError = 0.54296875 * 2560; time = 0.2738s; samplesPerSecond = 9350.9
MPI Rank 0: 02/03/2017 15:14:38:  Epoch[ 2 of 15]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 1.99184610 * 2560; EvalClassificationError = 0.55273438 * 2560; time = 0.2688s; samplesPerSecond = 9525.2
MPI Rank 0: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 1.98267472 * 2560; EvalClassificationError = 0.54023438 * 2560; time = 0.2859s; samplesPerSecond = 8955.2
MPI Rank 0: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 1.93130832 * 2560; EvalClassificationError = 0.52773437 * 2560; time = 0.2771s; samplesPerSecond = 9239.8
MPI Rank 0: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 1.91975734 * 2560; EvalClassificationError = 0.51718750 * 2560; time = 0.2690s; samplesPerSecond = 9516.7
MPI Rank 0: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 1.90691644 * 2560; EvalClassificationError = 0.52734375 * 2560; time = 0.2817s; samplesPerSecond = 9086.2
MPI Rank 0: 02/03/2017 15:14:39: Finished Epoch[ 2 of 15]: [Training] CrossEntropyWithSoftmax = 1.98262942 * 20480; EvalClassificationError = 0.53994141 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=2.24702s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:14:43: Final Results: Minibatch[1-326]: CrossEntropyWithSoftmax = 1.88974199 * 83050; perplexity = 6.61766107; EvalClassificationError = 0.52368453 * 83050
MPI Rank 0: 02/03/2017 15:14:43: Finished Epoch[ 2 of 15]: [Validate] CrossEntropyWithSoftmax = 1.88974199 * 83050; EvalClassificationError = 0.52368453 * 83050
MPI Rank 0: 02/03/2017 15:14:43: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.889742 (Epoch 2); EvalClassificationError = 0.523685 (Epoch 2)
MPI Rank 0: 02/03/2017 15:14:43: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:43: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:43: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:14:44:  Epoch[ 3 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.90951347 * 10240; EvalClassificationError = 0.52617187 * 10240; time = 0.9879s; samplesPerSecond = 10365.0
MPI Rank 0: 02/03/2017 15:14:45:  Epoch[ 3 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93082770 * 10240; EvalClassificationError = 0.54072266 * 10240; time = 0.9778s; samplesPerSecond = 10472.6
MPI Rank 0: 02/03/2017 15:14:45: Finished Epoch[ 3 of 15]: [Training] CrossEntropyWithSoftmax = 1.92017059 * 20480; EvalClassificationError = 0.53344727 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=1.97764s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:14:49: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.86850118 * 83050; perplexity = 6.47857889; EvalClassificationError = 0.51506321 * 83050
MPI Rank 0: 02/03/2017 15:14:49: Finished Epoch[ 3 of 15]: [Validate] CrossEntropyWithSoftmax = 1.86850118 * 83050; EvalClassificationError = 0.51506321 * 83050
MPI Rank 0: 02/03/2017 15:14:49: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.868501 (Epoch 3); EvalClassificationError = 0.515063 (Epoch 3)
MPI Rank 0: 02/03/2017 15:14:49: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:49: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:49: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:14:50:  Epoch[ 4 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.89764325 * 10240; EvalClassificationError = 0.52333984 * 10240; time = 0.9775s; samplesPerSecond = 10475.7
MPI Rank 0: 02/03/2017 15:14:51:  Epoch[ 4 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.88487176 * 10240; EvalClassificationError = 0.51748047 * 10240; time = 0.9565s; samplesPerSecond = 10705.4
MPI Rank 0: 02/03/2017 15:14:51: Finished Epoch[ 4 of 15]: [Training] CrossEntropyWithSoftmax = 1.89125751 * 20480; EvalClassificationError = 0.52041016 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=1.94577s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:14:54: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85983322 * 83050; perplexity = 6.42266551; EvalClassificationError = 0.51353402 * 83050
MPI Rank 0: 02/03/2017 15:14:54: Finished Epoch[ 4 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85983322 * 83050; EvalClassificationError = 0.51353402 * 83050
MPI Rank 0: 02/03/2017 15:14:54: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.859833 (Epoch 4); EvalClassificationError = 0.513534 (Epoch 4)
MPI Rank 0: 02/03/2017 15:14:54: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:54: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:14:54: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:14:55:  Epoch[ 5 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.89632684 * 10240; EvalClassificationError = 0.52275391 * 10240; time = 0.9965s; samplesPerSecond = 10275.6
MPI Rank 0: 02/03/2017 15:14:56:  Epoch[ 5 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.87614524 * 10240; EvalClassificationError = 0.51376953 * 10240; time = 0.9085s; samplesPerSecond = 11270.9
MPI Rank 0: 02/03/2017 15:14:56: Finished Epoch[ 5 of 15]: [Training] CrossEntropyWithSoftmax = 1.88623604 * 20480; EvalClassificationError = 0.51826172 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-005; epochTime=1.91642s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:00: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85220114 * 83050; perplexity = 6.37383377; EvalClassificationError = 0.51182420 * 83050
MPI Rank 0: 02/03/2017 15:15:00: Finished Epoch[ 5 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85220114 * 83050; EvalClassificationError = 0.51182420 * 83050
MPI Rank 0: 02/03/2017 15:15:00: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.852201 (Epoch 5); EvalClassificationError = 0.511824 (Epoch 5)
MPI Rank 0: 02/03/2017 15:15:00: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.5'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:00: Starting Epoch 6: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 5: frames [102400..122880] (first utterance at frame 102400), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:00: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:01:  Epoch[ 6 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.88778608 * 10240; EvalClassificationError = 0.52792969 * 10240; time = 0.9457s; samplesPerSecond = 10827.5
MPI Rank 0: 02/03/2017 15:15:02:  Epoch[ 6 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.86551311 * 10240; EvalClassificationError = 0.51181641 * 10240; time = 0.9390s; samplesPerSecond = 10905.6
MPI Rank 0: 02/03/2017 15:15:02: Finished Epoch[ 6 of 15]: [Training] CrossEntropyWithSoftmax = 1.87664959 * 20480; EvalClassificationError = 0.51987305 * 20480; totalSamplesSeen = 122880; learningRatePerSample = 9.7656251e-005; epochTime=1.89694s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:05: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.84540013 * 83050; perplexity = 6.33063233; EvalClassificationError = 0.51095725 * 83050
MPI Rank 0: 02/03/2017 15:15:05: Finished Epoch[ 6 of 15]: [Validate] CrossEntropyWithSoftmax = 1.84540013 * 83050; EvalClassificationError = 0.51095725 * 83050
MPI Rank 0: 02/03/2017 15:15:05: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.845400 (Epoch 6); EvalClassificationError = 0.510957 (Epoch 6)
MPI Rank 0: 02/03/2017 15:15:05: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.6'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:06: Starting Epoch 7: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 6: frames [122880..143360] (first utterance at frame 122880), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:06: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:06:  Epoch[ 7 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.84256004 * 10240; EvalClassificationError = 0.50625000 * 10240; time = 0.8847s; samplesPerSecond = 11574.7
MPI Rank 0: 02/03/2017 15:15:07:  Epoch[ 7 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.87222039 * 10240; EvalClassificationError = 0.52236328 * 10240; time = 0.8772s; samplesPerSecond = 11673.0
MPI Rank 0: 02/03/2017 15:15:07: Finished Epoch[ 7 of 15]: [Training] CrossEntropyWithSoftmax = 1.85739021 * 20480; EvalClassificationError = 0.51430664 * 20480; totalSamplesSeen = 143360; learningRatePerSample = 9.7656251e-005; epochTime=1.77314s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:11: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83871518 * 83050; perplexity = 6.28845352; EvalClassificationError = 0.50976520 * 83050
MPI Rank 0: 02/03/2017 15:15:11: Finished Epoch[ 7 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83871518 * 83050; EvalClassificationError = 0.50976520 * 83050
MPI Rank 0: 02/03/2017 15:15:11: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.838715 (Epoch 7); EvalClassificationError = 0.509765 (Epoch 7)
MPI Rank 0: 02/03/2017 15:15:11: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.7'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:11: Starting Epoch 8: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 7: frames [143360..163840] (first utterance at frame 143360), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:11: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:12:  Epoch[ 8 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.84987109 * 10240; EvalClassificationError = 0.51123047 * 10240; time = 0.8802s; samplesPerSecond = 11634.3
MPI Rank 0: 02/03/2017 15:15:13:  Epoch[ 8 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.83192697 * 10240; EvalClassificationError = 0.51230469 * 10240; time = 0.9173s; samplesPerSecond = 11162.8
MPI Rank 0: 02/03/2017 15:15:13: Finished Epoch[ 8 of 15]: [Training] CrossEntropyWithSoftmax = 1.84089903 * 20480; EvalClassificationError = 0.51176758 * 20480; totalSamplesSeen = 163840; learningRatePerSample = 9.7656251e-005; epochTime=1.80844s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:16: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83368155 * 83050; perplexity = 6.25687930; EvalClassificationError = 0.50872968 * 83050
MPI Rank 0: 02/03/2017 15:15:16: Finished Epoch[ 8 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83368155 * 83050; EvalClassificationError = 0.50872968 * 83050
MPI Rank 0: 02/03/2017 15:15:16: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.833682 (Epoch 8); EvalClassificationError = 0.508730 (Epoch 8)
MPI Rank 0: 02/03/2017 15:15:16: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.8'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:16: Starting Epoch 9: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 8: frames [163840..184320] (first utterance at frame 163840), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:16: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:17:  Epoch[ 9 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.82611619 * 10240; EvalClassificationError = 0.50000000 * 10240; time = 0.9540s; samplesPerSecond = 10734.1
MPI Rank 0: 02/03/2017 15:15:18:  Epoch[ 9 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.82514435 * 10240; EvalClassificationError = 0.51201172 * 10240; time = 0.8995s; samplesPerSecond = 11384.6
MPI Rank 0: 02/03/2017 15:15:18: Finished Epoch[ 9 of 15]: [Training] CrossEntropyWithSoftmax = 1.82563027 * 20480; EvalClassificationError = 0.50600586 * 20480; totalSamplesSeen = 184320; learningRatePerSample = 9.7656251e-005; epochTime=1.86454s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:22: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82727362 * 83050; perplexity = 6.21691389; EvalClassificationError = 0.50915111 * 83050
MPI Rank 0: 02/03/2017 15:15:22: Finished Epoch[ 9 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82727362 * 83050; EvalClassificationError = 0.50915111 * 83050
MPI Rank 0: 02/03/2017 15:15:22: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.827274 (Epoch 9); EvalClassificationError = 0.508730 (Epoch 8)
MPI Rank 0: 02/03/2017 15:15:22: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.9'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:22: Starting Epoch 10: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 9: frames [184320..204800] (first utterance at frame 184320), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:22: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:23:  Epoch[10 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.85901376 * 10240; EvalClassificationError = 0.51806641 * 10240; time = 1.0300s; samplesPerSecond = 9941.6
MPI Rank 0: 02/03/2017 15:15:24:  Epoch[10 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81251665 * 10240; EvalClassificationError = 0.50283203 * 10240; time = 0.9747s; samplesPerSecond = 10505.3
MPI Rank 0: 02/03/2017 15:15:24: Finished Epoch[10 of 15]: [Training] CrossEntropyWithSoftmax = 1.83576521 * 20480; EvalClassificationError = 0.51044922 * 20480; totalSamplesSeen = 204800; learningRatePerSample = 9.7656251e-005; epochTime=2.01776s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:27: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82126579 * 83050; perplexity = 6.17967570; EvalClassificationError = 0.50791090 * 83050
MPI Rank 0: 02/03/2017 15:15:27: Finished Epoch[10 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82126579 * 83050; EvalClassificationError = 0.50791090 * 83050
MPI Rank 0: 02/03/2017 15:15:27: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.821266 (Epoch 10); EvalClassificationError = 0.507911 (Epoch 10)
MPI Rank 0: 02/03/2017 15:15:27: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.10'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:27: Starting Epoch 11: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 10: frames [204800..225280] (first utterance at frame 204800), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:27: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:28:  Epoch[11 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.82889710 * 10240; EvalClassificationError = 0.49960938 * 10240; time = 0.9694s; samplesPerSecond = 10563.0
MPI Rank 0: 02/03/2017 15:15:29:  Epoch[11 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.82839820 * 10240; EvalClassificationError = 0.51210937 * 10240; time = 0.9432s; samplesPerSecond = 10856.9
MPI Rank 0: 02/03/2017 15:15:29: Finished Epoch[11 of 15]: [Training] CrossEntropyWithSoftmax = 1.82864765 * 20480; EvalClassificationError = 0.50585938 * 20480; totalSamplesSeen = 225280; learningRatePerSample = 9.7656251e-005; epochTime=1.92614s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:33: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.81468075 * 83050; perplexity = 6.13911593; EvalClassificationError = 0.50450331 * 83050
MPI Rank 0: 02/03/2017 15:15:33: Finished Epoch[11 of 15]: [Validate] CrossEntropyWithSoftmax = 1.81468075 * 83050; EvalClassificationError = 0.50450331 * 83050
MPI Rank 0: 02/03/2017 15:15:33: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.814681 (Epoch 11); EvalClassificationError = 0.504503 (Epoch 11)
MPI Rank 0: 02/03/2017 15:15:33: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.11'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:33: Starting Epoch 12: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 11: frames [225280..245760] (first utterance at frame 225280), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:33: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:34:  Epoch[12 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.83173777 * 10240; EvalClassificationError = 0.50830078 * 10240; time = 0.9401s; samplesPerSecond = 10892.0
MPI Rank 0: 02/03/2017 15:15:35:  Epoch[12 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.80223414 * 10240; EvalClassificationError = 0.49677734 * 10240; time = 0.9009s; samplesPerSecond = 11365.9
MPI Rank 0: 02/03/2017 15:15:35: Finished Epoch[12 of 15]: [Training] CrossEntropyWithSoftmax = 1.81698596 * 20480; EvalClassificationError = 0.50253906 * 20480; totalSamplesSeen = 245760; learningRatePerSample = 9.7656251e-005; epochTime=1.85164s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:39: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.80857265 * 83050; perplexity = 6.10173188; EvalClassificationError = 0.50361228 * 83050
MPI Rank 0: 02/03/2017 15:15:39: Finished Epoch[12 of 15]: [Validate] CrossEntropyWithSoftmax = 1.80857265 * 83050; EvalClassificationError = 0.50361228 * 83050
MPI Rank 0: 02/03/2017 15:15:39: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.808573 (Epoch 12); EvalClassificationError = 0.503612 (Epoch 12)
MPI Rank 0: 02/03/2017 15:15:39: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.12'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:39: Starting Epoch 13: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 12: frames [245760..266240] (first utterance at frame 245760), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:39: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:40:  Epoch[13 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.80988074 * 10046; EvalClassificationError = 0.50696795 * 10046; time = 0.9939s; samplesPerSecond = 10107.2
MPI Rank 0: 02/03/2017 15:15:41:  Epoch[13 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84128702 * 10240; EvalClassificationError = 0.51132813 * 10240; time = 0.9642s; samplesPerSecond = 10620.6
MPI Rank 0: 02/03/2017 15:15:41: Finished Epoch[13 of 15]: [Training] CrossEntropyWithSoftmax = 1.82642072 * 20480; EvalClassificationError = 0.50888672 * 20480; totalSamplesSeen = 266240; learningRatePerSample = 9.7656251e-005; epochTime=1.99227s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:44: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.80252013 * 83050; perplexity = 6.06491260; EvalClassificationError = 0.50139675 * 83050
MPI Rank 0: 02/03/2017 15:15:44: Finished Epoch[13 of 15]: [Validate] CrossEntropyWithSoftmax = 1.80252013 * 83050; EvalClassificationError = 0.50139675 * 83050
MPI Rank 0: 02/03/2017 15:15:44: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.802520 (Epoch 13); EvalClassificationError = 0.501397 (Epoch 13)
MPI Rank 0: 02/03/2017 15:15:44: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.13'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:44: Starting Epoch 14: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 13: frames [266240..286720] (first utterance at frame 266240), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:44: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:45:  Epoch[14 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.82363588 * 10240; EvalClassificationError = 0.49697266 * 10240; time = 0.9698s; samplesPerSecond = 10558.4
MPI Rank 0: 02/03/2017 15:15:46:  Epoch[14 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81095529 * 10240; EvalClassificationError = 0.50312500 * 10240; time = 0.9913s; samplesPerSecond = 10330.3
MPI Rank 0: 02/03/2017 15:15:46: Finished Epoch[14 of 15]: [Training] CrossEntropyWithSoftmax = 1.81729558 * 20480; EvalClassificationError = 0.50004883 * 20480; totalSamplesSeen = 286720; learningRatePerSample = 9.7656251e-005; epochTime=1.97437s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:50: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.79721110 * 83050; perplexity = 6.03279911; EvalClassificationError = 0.50168573 * 83050
MPI Rank 0: 02/03/2017 15:15:50: Finished Epoch[14 of 15]: [Validate] CrossEntropyWithSoftmax = 1.79721110 * 83050; EvalClassificationError = 0.50168573 * 83050
MPI Rank 0: 02/03/2017 15:15:50: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.797211 (Epoch 14); EvalClassificationError = 0.501397 (Epoch 13)
MPI Rank 0: 02/03/2017 15:15:50: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.14'
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:50: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 14: frames [286720..307200] (first utterance at frame 286720), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:50: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:51:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.78626990 * 10240; EvalClassificationError = 0.49990234 * 10240; time = 1.0349s; samplesPerSecond = 9894.4
MPI Rank 0: 02/03/2017 15:15:52:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81093423 * 10240; EvalClassificationError = 0.50566406 * 10240; time = 1.0324s; samplesPerSecond = 9919.1
MPI Rank 0: 02/03/2017 15:15:52: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.79860207 * 20480; EvalClassificationError = 0.50278320 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-005; epochTime=2.07975s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 02/03/2017 15:15:55: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.79156270 * 83050; perplexity = 5.99881948; EvalClassificationError = 0.50039735 * 83050
MPI Rank 0: 02/03/2017 15:15:55: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.79156270 * 83050; EvalClassificationError = 0.50039735 * 83050
MPI Rank 0: 02/03/2017 15:15:55: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.791563 (Epoch 15); EvalClassificationError = 0.500397 (Epoch 15)
MPI Rank 0: 02/03/2017 15:15:56: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn'
MPI Rank 0: 02/03/2017 15:15:56: Best epoch for criterion 'CrossEntropyWithSoftmax' is 15 and model C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn copied to C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn_CrossEntropyWithSoftmax
MPI Rank 0: 02/03/2017 15:15:56: Best epoch for criterion 'EvalClassificationError' is 15 and model C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn copied to C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn_EvalClassificationError
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: __COMPLETED__
MPI Rank 1: 02/03/2017 15:14:24: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr_speechTrain.logrank1
MPI Rank 1: CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:14:24
MPI Rank 1: 
MPI Rank 1: D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
MPI Rank 1: 02/03/2017 15:14:24: Using 4 CPU threads.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:24: ##############################################################################
MPI Rank 1: 02/03/2017 15:14:24: #                                                                            #
MPI Rank 1: 02/03/2017 15:14:24: # speechTrain command (train action)                                         #
MPI Rank 1: 02/03/2017 15:14:24: #                                                                            #
MPI Rank 1: 02/03/2017 15:14:24: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:24: 
MPI Rank 1: Creating virgin network.
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 1: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...........................................................................feature set 0: 83050 frames in 300 out of 300 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 300 utterances grouped into 1 chunks, av. chunk size: 300.0 utterances, 83050.0 frames
MPI Rank 1: 02/03/2017 15:14:25: 
MPI Rank 1: Model has 25 nodes. Using CPU.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:25: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 02/03/2017 15:14:25: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing: Out of 40 matrices, 21 are shared as 7, and 19 are not shared.
MPI Rank 1: 
MPI Rank 1: 	{ B0 : [512 x 1] (gradient)
MPI Rank 1: 	  H1 : [512 x 1 x *] (gradient) }
MPI Rank 1: 	{ W1 : [512 x 512] (gradient)
MPI Rank 1: 	  W1*H1+B1 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  W2*H1 : [132 x 1 x *] (gradient) }
MPI Rank 1: 	{ HLast : [132 x 1 x *]
MPI Rank 1: 	  W2 : [132 x 512] (gradient) }
MPI Rank 1: 	{ H2 : [512 x 1 x *]
MPI Rank 1: 	  W0 : [512 x 363] (gradient)
MPI Rank 1: 	  W0*features+B0 : [512 x 1 x *]
MPI Rank 1: 	  W0*features+B0 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  W1*H1 : [512 x 1 x *]
MPI Rank 1: 	  W1*H1 : [512 x 1 x *] (gradient) }
MPI Rank 1: 	{ B1 : [512 x 1] (gradient)
MPI Rank 1: 	  H2 : [512 x 1 x *] (gradient)
MPI Rank 1: 	  HLast : [132 x 1 x *] (gradient) }
MPI Rank 1: 	{ W1*H1+B1 : [512 x 1 x *]
MPI Rank 1: 	  W2*H1 : [132 x 1 x *] }
MPI Rank 1: 	{ H1 : [512 x 1 x *]
MPI Rank 1: 	  W0*features : [512 x *]
MPI Rank 1: 	  W0*features : [512 x *] (gradient) }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:25: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:25: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 02/03/2017 15:14:25: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 02/03/2017 15:14:25: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 1: 02/03/2017 15:14:25: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 1: 02/03/2017 15:14:25: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 1: 02/03/2017 15:14:25: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 1: 
MPI Rank 1: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:25: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:25: 	MeanOfFeatures = Mean()
MPI Rank 1: 02/03/2017 15:14:25: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 02/03/2017 15:14:25: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:28: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:28: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:28: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[   1-  10, 3.13%]: CrossEntropyWithSoftmax = 4.56731190 * 640; EvalClassificationError = 0.91718750 * 640; time = 0.1391s; samplesPerSecond = 4600.8
MPI Rank 1: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.31208878 * 640; EvalClassificationError = 0.92812500 * 640; time = 0.1311s; samplesPerSecond = 4883.5
MPI Rank 1: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 3.97319840 * 640; EvalClassificationError = 0.87343750 * 640; time = 0.1289s; samplesPerSecond = 4966.8
MPI Rank 1: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.73308124 * 640; EvalClassificationError = 0.84531250 * 640; time = 0.1331s; samplesPerSecond = 4810.0
MPI Rank 1: 02/03/2017 15:14:28:  Epoch[ 1 of 15]-Minibatch[  41-  50, 15.63%]: CrossEntropyWithSoftmax = 3.83238242 * 640; EvalClassificationError = 0.86406250 * 640; time = 0.1470s; samplesPerSecond = 4354.1
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.69914238 * 640; EvalClassificationError = 0.86093750 * 640; time = 0.1356s; samplesPerSecond = 4720.8
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.40238588 * 640; EvalClassificationError = 0.77812500 * 640; time = 0.1355s; samplesPerSecond = 4722.2
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.51740313 * 640; EvalClassificationError = 0.83750000 * 640; time = 0.1217s; samplesPerSecond = 5260.7
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  81-  90, 28.13%]: CrossEntropyWithSoftmax = 3.50059778 * 640; EvalClassificationError = 0.81250000 * 640; time = 0.1231s; samplesPerSecond = 5201.0
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.39301549 * 640; EvalClassificationError = 0.80156250 * 640; time = 0.1248s; samplesPerSecond = 5129.5
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.48832144 * 640; EvalClassificationError = 0.82187500 * 640; time = 0.1275s; samplesPerSecond = 5020.2
MPI Rank 1: 02/03/2017 15:14:29:  Epoch[ 1 of 15]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.23814723 * 640; EvalClassificationError = 0.77031250 * 640; time = 0.1575s; samplesPerSecond = 4062.8
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 121- 130, 40.63%]: CrossEntropyWithSoftmax = 3.14333583 * 640; EvalClassificationError = 0.76093750 * 640; time = 0.1609s; samplesPerSecond = 3976.7
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 3.01547841 * 640; EvalClassificationError = 0.73906250 * 640; time = 0.1403s; samplesPerSecond = 4562.0
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91114805 * 640; EvalClassificationError = 0.71093750 * 640; time = 0.1321s; samplesPerSecond = 4844.7
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.06450741 * 640; EvalClassificationError = 0.74375000 * 640; time = 0.1460s; samplesPerSecond = 4384.9
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 161- 170, 53.13%]: CrossEntropyWithSoftmax = 2.77009796 * 640; EvalClassificationError = 0.69531250 * 640; time = 0.1437s; samplesPerSecond = 4455.1
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.67234909 * 640; EvalClassificationError = 0.64531250 * 640; time = 0.1466s; samplesPerSecond = 4367.1
MPI Rank 1: 02/03/2017 15:14:30:  Epoch[ 1 of 15]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.76324613 * 640; EvalClassificationError = 0.69843750 * 640; time = 0.1520s; samplesPerSecond = 4211.2
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.70050608 * 640; EvalClassificationError = 0.68125000 * 640; time = 0.1547s; samplesPerSecond = 4136.9
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 201- 210, 65.63%]: CrossEntropyWithSoftmax = 2.56019594 * 640; EvalClassificationError = 0.65312500 * 640; time = 0.1488s; samplesPerSecond = 4301.4
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.56796356 * 640; EvalClassificationError = 0.63906250 * 640; time = 0.1380s; samplesPerSecond = 4638.2
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.51054929 * 640; EvalClassificationError = 0.65000000 * 640; time = 0.1328s; samplesPerSecond = 4817.9
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.52174700 * 640; EvalClassificationError = 0.65468750 * 640; time = 0.1311s; samplesPerSecond = 4882.7
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 241- 250, 78.13%]: CrossEntropyWithSoftmax = 2.45943503 * 640; EvalClassificationError = 0.62812500 * 640; time = 0.1315s; samplesPerSecond = 4867.5
MPI Rank 1: 02/03/2017 15:14:31:  Epoch[ 1 of 15]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.36070476 * 640; EvalClassificationError = 0.62031250 * 640; time = 0.1439s; samplesPerSecond = 4447.3
MPI Rank 1: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.22167676 * 640; EvalClassificationError = 0.58125000 * 640; time = 0.1396s; samplesPerSecond = 4582.9
MPI Rank 1: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.48104909 * 640; EvalClassificationError = 0.66093750 * 640; time = 0.1419s; samplesPerSecond = 4510.6
MPI Rank 1: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 281- 290, 90.63%]: CrossEntropyWithSoftmax = 2.23253572 * 640; EvalClassificationError = 0.58906250 * 640; time = 0.1416s; samplesPerSecond = 4520.5
MPI Rank 1: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.22145425 * 640; EvalClassificationError = 0.60312500 * 640; time = 0.1679s; samplesPerSecond = 3812.8
MPI Rank 1: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.21771892 * 640; EvalClassificationError = 0.58125000 * 640; time = 0.1459s; samplesPerSecond = 4386.8
MPI Rank 1: 02/03/2017 15:14:32:  Epoch[ 1 of 15]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.19995645 * 640; EvalClassificationError = 0.59843750 * 640; time = 0.1343s; samplesPerSecond = 4767.0
MPI Rank 1: 02/03/2017 15:14:32: Finished Epoch[ 1 of 15]: [Training] CrossEntropyWithSoftmax = 3.00789787 * 20480; EvalClassificationError = 0.72641602 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=4.5119s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:14:37: Final Results: Minibatch[1-1299]: CrossEntropyWithSoftmax = 2.20991696 * 83050; perplexity = 9.11495943; EvalClassificationError = 0.60792294 * 83050
MPI Rank 1: 02/03/2017 15:14:37: Finished Epoch[ 1 of 15]: [Validate] CrossEntropyWithSoftmax = 2.20991696 * 83050; EvalClassificationError = 0.60792294 * 83050
MPI Rank 1: 02/03/2017 15:14:37: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 2.209917 (Epoch 1); EvalClassificationError = 0.607923 (Epoch 1)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:37: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:37: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:14:37:  Epoch[ 2 of 15]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.09963072 * 2560; EvalClassificationError = 0.56132812 * 2560; time = 0.2786s; samplesPerSecond = 9189.9
MPI Rank 1: 02/03/2017 15:14:38:  Epoch[ 2 of 15]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.02412622 * 2560; EvalClassificationError = 0.55000000 * 2560; time = 0.2999s; samplesPerSecond = 8536.4
MPI Rank 1: 02/03/2017 15:14:38:  Epoch[ 2 of 15]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.00477550 * 2560; EvalClassificationError = 0.54296875 * 2560; time = 0.2735s; samplesPerSecond = 9361.5
MPI Rank 1: 02/03/2017 15:14:38:  Epoch[ 2 of 15]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 1.99184610 * 2560; EvalClassificationError = 0.55273438 * 2560; time = 0.2691s; samplesPerSecond = 9514.6
MPI Rank 1: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 1.98267472 * 2560; EvalClassificationError = 0.54023438 * 2560; time = 0.2861s; samplesPerSecond = 8949.1
MPI Rank 1: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 1.93130832 * 2560; EvalClassificationError = 0.52773437 * 2560; time = 0.2767s; samplesPerSecond = 9251.2
MPI Rank 1: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 1.91975734 * 2560; EvalClassificationError = 0.51718750 * 2560; time = 0.2691s; samplesPerSecond = 9513.2
MPI Rank 1: 02/03/2017 15:14:39:  Epoch[ 2 of 15]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 1.90691644 * 2560; EvalClassificationError = 0.52734375 * 2560; time = 0.2820s; samplesPerSecond = 9076.5
MPI Rank 1: 02/03/2017 15:14:39: Finished Epoch[ 2 of 15]: [Training] CrossEntropyWithSoftmax = 1.98262942 * 20480; EvalClassificationError = 0.53994141 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=2.24702s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:14:43: Final Results: Minibatch[1-326]: CrossEntropyWithSoftmax = 1.88974199 * 83050; perplexity = 6.61766107; EvalClassificationError = 0.52368453 * 83050
MPI Rank 1: 02/03/2017 15:14:43: Finished Epoch[ 2 of 15]: [Validate] CrossEntropyWithSoftmax = 1.88974199 * 83050; EvalClassificationError = 0.52368453 * 83050
MPI Rank 1: 02/03/2017 15:14:43: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.889742 (Epoch 2); EvalClassificationError = 0.523685 (Epoch 2)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:43: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:43: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:14:44:  Epoch[ 3 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.90951347 * 10240; EvalClassificationError = 0.52617187 * 10240; time = 0.9900s; samplesPerSecond = 10343.3
MPI Rank 1: 02/03/2017 15:14:45:  Epoch[ 3 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93082770 * 10240; EvalClassificationError = 0.54072266 * 10240; time = 0.9777s; samplesPerSecond = 10473.8
MPI Rank 1: 02/03/2017 15:14:45: Finished Epoch[ 3 of 15]: [Training] CrossEntropyWithSoftmax = 1.92017059 * 20480; EvalClassificationError = 0.53344727 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=1.9776s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:14:49: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.86850118 * 83050; perplexity = 6.47857889; EvalClassificationError = 0.51506321 * 83050
MPI Rank 1: 02/03/2017 15:14:49: Finished Epoch[ 3 of 15]: [Validate] CrossEntropyWithSoftmax = 1.86850118 * 83050; EvalClassificationError = 0.51506321 * 83050
MPI Rank 1: 02/03/2017 15:14:49: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.868501 (Epoch 3); EvalClassificationError = 0.515063 (Epoch 3)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:49: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:49: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:14:50:  Epoch[ 4 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.89764325 * 10240; EvalClassificationError = 0.52333984 * 10240; time = 0.9794s; samplesPerSecond = 10455.1
MPI Rank 1: 02/03/2017 15:14:51:  Epoch[ 4 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.88487176 * 10240; EvalClassificationError = 0.51748047 * 10240; time = 0.9564s; samplesPerSecond = 10706.7
MPI Rank 1: 02/03/2017 15:14:51: Finished Epoch[ 4 of 15]: [Training] CrossEntropyWithSoftmax = 1.89125751 * 20480; EvalClassificationError = 0.52041016 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=1.94576s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:14:54: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85983322 * 83050; perplexity = 6.42266551; EvalClassificationError = 0.51353402 * 83050
MPI Rank 1: 02/03/2017 15:14:54: Finished Epoch[ 4 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85983322 * 83050; EvalClassificationError = 0.51353402 * 83050
MPI Rank 1: 02/03/2017 15:14:54: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.859833 (Epoch 4); EvalClassificationError = 0.513534 (Epoch 4)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:54: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:14:54: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:14:55:  Epoch[ 5 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.89632684 * 10240; EvalClassificationError = 0.52275391 * 10240; time = 0.9975s; samplesPerSecond = 10265.3
MPI Rank 1: 02/03/2017 15:14:56:  Epoch[ 5 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.87614524 * 10240; EvalClassificationError = 0.51376953 * 10240; time = 0.9084s; samplesPerSecond = 11272.4
MPI Rank 1: 02/03/2017 15:14:56: Finished Epoch[ 5 of 15]: [Training] CrossEntropyWithSoftmax = 1.88623604 * 20480; EvalClassificationError = 0.51826172 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-005; epochTime=1.91637s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:00: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.85220114 * 83050; perplexity = 6.37383377; EvalClassificationError = 0.51182420 * 83050
MPI Rank 1: 02/03/2017 15:15:00: Finished Epoch[ 5 of 15]: [Validate] CrossEntropyWithSoftmax = 1.85220114 * 83050; EvalClassificationError = 0.51182420 * 83050
MPI Rank 1: 02/03/2017 15:15:00: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.852201 (Epoch 5); EvalClassificationError = 0.511824 (Epoch 5)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:00: Starting Epoch 6: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 5: frames [102400..122880] (first utterance at frame 102400), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:00: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:01:  Epoch[ 6 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.88778608 * 10240; EvalClassificationError = 0.52792969 * 10240; time = 0.9481s; samplesPerSecond = 10801.0
MPI Rank 1: 02/03/2017 15:15:02:  Epoch[ 6 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.86551311 * 10240; EvalClassificationError = 0.51181641 * 10240; time = 0.9387s; samplesPerSecond = 10908.4
MPI Rank 1: 02/03/2017 15:15:02: Finished Epoch[ 6 of 15]: [Training] CrossEntropyWithSoftmax = 1.87664959 * 20480; EvalClassificationError = 0.51987305 * 20480; totalSamplesSeen = 122880; learningRatePerSample = 9.7656251e-005; epochTime=1.89693s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:05: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.84540013 * 83050; perplexity = 6.33063233; EvalClassificationError = 0.51095725 * 83050
MPI Rank 1: 02/03/2017 15:15:05: Finished Epoch[ 6 of 15]: [Validate] CrossEntropyWithSoftmax = 1.84540013 * 83050; EvalClassificationError = 0.51095725 * 83050
MPI Rank 1: 02/03/2017 15:15:05: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.845400 (Epoch 6); EvalClassificationError = 0.510957 (Epoch 6)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:06: Starting Epoch 7: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 6: frames [122880..143360] (first utterance at frame 122880), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:06: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:06:  Epoch[ 7 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.84256004 * 10240; EvalClassificationError = 0.50625000 * 10240; time = 0.8864s; samplesPerSecond = 11551.9
MPI Rank 1: 02/03/2017 15:15:07:  Epoch[ 7 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.87222039 * 10240; EvalClassificationError = 0.52236328 * 10240; time = 0.8775s; samplesPerSecond = 11669.8
MPI Rank 1: 02/03/2017 15:15:07: Finished Epoch[ 7 of 15]: [Training] CrossEntropyWithSoftmax = 1.85739021 * 20480; EvalClassificationError = 0.51430664 * 20480; totalSamplesSeen = 143360; learningRatePerSample = 9.7656251e-005; epochTime=1.7731s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:11: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83871518 * 83050; perplexity = 6.28845352; EvalClassificationError = 0.50976520 * 83050
MPI Rank 1: 02/03/2017 15:15:11: Finished Epoch[ 7 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83871518 * 83050; EvalClassificationError = 0.50976520 * 83050
MPI Rank 1: 02/03/2017 15:15:11: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.838715 (Epoch 7); EvalClassificationError = 0.509765 (Epoch 7)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:11: Starting Epoch 8: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 7: frames [143360..163840] (first utterance at frame 143360), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:11: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:12:  Epoch[ 8 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.84987109 * 10240; EvalClassificationError = 0.51123047 * 10240; time = 0.8807s; samplesPerSecond = 11626.9
MPI Rank 1: 02/03/2017 15:15:13:  Epoch[ 8 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.83192697 * 10240; EvalClassificationError = 0.51230469 * 10240; time = 0.9180s; samplesPerSecond = 11155.2
MPI Rank 1: 02/03/2017 15:15:13: Finished Epoch[ 8 of 15]: [Training] CrossEntropyWithSoftmax = 1.84089903 * 20480; EvalClassificationError = 0.51176758 * 20480; totalSamplesSeen = 163840; learningRatePerSample = 9.7656251e-005; epochTime=1.80841s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:16: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.83368155 * 83050; perplexity = 6.25687930; EvalClassificationError = 0.50872968 * 83050
MPI Rank 1: 02/03/2017 15:15:16: Finished Epoch[ 8 of 15]: [Validate] CrossEntropyWithSoftmax = 1.83368155 * 83050; EvalClassificationError = 0.50872968 * 83050
MPI Rank 1: 02/03/2017 15:15:16: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.833682 (Epoch 8); EvalClassificationError = 0.508730 (Epoch 8)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:16: Starting Epoch 9: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 8: frames [163840..184320] (first utterance at frame 163840), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:16: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:17:  Epoch[ 9 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.82611619 * 10240; EvalClassificationError = 0.50000000 * 10240; time = 0.9561s; samplesPerSecond = 10710.3
MPI Rank 1: 02/03/2017 15:15:18:  Epoch[ 9 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.82514435 * 10240; EvalClassificationError = 0.51201172 * 10240; time = 0.8994s; samplesPerSecond = 11385.7
MPI Rank 1: 02/03/2017 15:15:18: Finished Epoch[ 9 of 15]: [Training] CrossEntropyWithSoftmax = 1.82563027 * 20480; EvalClassificationError = 0.50600586 * 20480; totalSamplesSeen = 184320; learningRatePerSample = 9.7656251e-005; epochTime=1.86454s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:22: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82727362 * 83050; perplexity = 6.21691389; EvalClassificationError = 0.50915111 * 83050
MPI Rank 1: 02/03/2017 15:15:22: Finished Epoch[ 9 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82727362 * 83050; EvalClassificationError = 0.50915111 * 83050
MPI Rank 1: 02/03/2017 15:15:22: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.827274 (Epoch 9); EvalClassificationError = 0.508730 (Epoch 8)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:22: Starting Epoch 10: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 9: frames [184320..204800] (first utterance at frame 184320), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:22: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:23:  Epoch[10 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.85901376 * 10240; EvalClassificationError = 0.51806641 * 10240; time = 1.0329s; samplesPerSecond = 9914.0
MPI Rank 1: 02/03/2017 15:15:24:  Epoch[10 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81251665 * 10240; EvalClassificationError = 0.50283203 * 10240; time = 0.9747s; samplesPerSecond = 10505.3
MPI Rank 1: 02/03/2017 15:15:24: Finished Epoch[10 of 15]: [Training] CrossEntropyWithSoftmax = 1.83576521 * 20480; EvalClassificationError = 0.51044922 * 20480; totalSamplesSeen = 204800; learningRatePerSample = 9.7656251e-005; epochTime=2.01775s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:27: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.82126579 * 83050; perplexity = 6.17967570; EvalClassificationError = 0.50791090 * 83050
MPI Rank 1: 02/03/2017 15:15:27: Finished Epoch[10 of 15]: [Validate] CrossEntropyWithSoftmax = 1.82126579 * 83050; EvalClassificationError = 0.50791090 * 83050
MPI Rank 1: 02/03/2017 15:15:27: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.821266 (Epoch 10); EvalClassificationError = 0.507911 (Epoch 10)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:27: Starting Epoch 11: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 10: frames [204800..225280] (first utterance at frame 204800), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:27: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:28:  Epoch[11 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.82889710 * 10240; EvalClassificationError = 0.49960938 * 10240; time = 0.9725s; samplesPerSecond = 10529.5
MPI Rank 1: 02/03/2017 15:15:29:  Epoch[11 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.82839820 * 10240; EvalClassificationError = 0.51210937 * 10240; time = 0.9422s; samplesPerSecond = 10867.9
MPI Rank 1: 02/03/2017 15:15:29: Finished Epoch[11 of 15]: [Training] CrossEntropyWithSoftmax = 1.82864765 * 20480; EvalClassificationError = 0.50585938 * 20480; totalSamplesSeen = 225280; learningRatePerSample = 9.7656251e-005; epochTime=1.92613s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:33: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.81468075 * 83050; perplexity = 6.13911593; EvalClassificationError = 0.50450331 * 83050
MPI Rank 1: 02/03/2017 15:15:33: Finished Epoch[11 of 15]: [Validate] CrossEntropyWithSoftmax = 1.81468075 * 83050; EvalClassificationError = 0.50450331 * 83050
MPI Rank 1: 02/03/2017 15:15:33: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.814681 (Epoch 11); EvalClassificationError = 0.504503 (Epoch 11)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:33: Starting Epoch 12: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 11: frames [225280..245760] (first utterance at frame 225280), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:33: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:34:  Epoch[12 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.83173777 * 10240; EvalClassificationError = 0.50830078 * 10240; time = 0.9415s; samplesPerSecond = 10875.8
MPI Rank 1: 02/03/2017 15:15:35:  Epoch[12 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.80223414 * 10240; EvalClassificationError = 0.49677734 * 10240; time = 0.9007s; samplesPerSecond = 11369.2
MPI Rank 1: 02/03/2017 15:15:35: Finished Epoch[12 of 15]: [Training] CrossEntropyWithSoftmax = 1.81698596 * 20480; EvalClassificationError = 0.50253906 * 20480; totalSamplesSeen = 245760; learningRatePerSample = 9.7656251e-005; epochTime=1.85164s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:39: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.80857265 * 83050; perplexity = 6.10173188; EvalClassificationError = 0.50361228 * 83050
MPI Rank 1: 02/03/2017 15:15:39: Finished Epoch[12 of 15]: [Validate] CrossEntropyWithSoftmax = 1.80857265 * 83050; EvalClassificationError = 0.50361228 * 83050
MPI Rank 1: 02/03/2017 15:15:39: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.808573 (Epoch 12); EvalClassificationError = 0.503612 (Epoch 12)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:39: Starting Epoch 13: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 12: frames [245760..266240] (first utterance at frame 245760), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:39: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:40:  Epoch[13 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.80988074 * 10046; EvalClassificationError = 0.50696795 * 10046; time = 0.9964s; samplesPerSecond = 10082.1
MPI Rank 1: 02/03/2017 15:15:41:  Epoch[13 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.84128702 * 10240; EvalClassificationError = 0.51132813 * 10240; time = 0.9643s; samplesPerSecond = 10619.0
MPI Rank 1: 02/03/2017 15:15:41: Finished Epoch[13 of 15]: [Training] CrossEntropyWithSoftmax = 1.82642072 * 20480; EvalClassificationError = 0.50888672 * 20480; totalSamplesSeen = 266240; learningRatePerSample = 9.7656251e-005; epochTime=1.99227s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:44: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.80252013 * 83050; perplexity = 6.06491260; EvalClassificationError = 0.50139675 * 83050
MPI Rank 1: 02/03/2017 15:15:44: Finished Epoch[13 of 15]: [Validate] CrossEntropyWithSoftmax = 1.80252013 * 83050; EvalClassificationError = 0.50139675 * 83050
MPI Rank 1: 02/03/2017 15:15:44: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.802520 (Epoch 13); EvalClassificationError = 0.501397 (Epoch 13)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:44: Starting Epoch 14: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 13: frames [266240..286720] (first utterance at frame 266240), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:44: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:45:  Epoch[14 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.82363588 * 10240; EvalClassificationError = 0.49697266 * 10240; time = 0.9736s; samplesPerSecond = 10518.0
MPI Rank 1: 02/03/2017 15:15:46:  Epoch[14 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81095529 * 10240; EvalClassificationError = 0.50312500 * 10240; time = 0.9912s; samplesPerSecond = 10330.8
MPI Rank 1: 02/03/2017 15:15:46: Finished Epoch[14 of 15]: [Training] CrossEntropyWithSoftmax = 1.81729558 * 20480; EvalClassificationError = 0.50004883 * 20480; totalSamplesSeen = 286720; learningRatePerSample = 9.7656251e-005; epochTime=1.97436s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:50: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.79721110 * 83050; perplexity = 6.03279911; EvalClassificationError = 0.50168573 * 83050
MPI Rank 1: 02/03/2017 15:15:50: Finished Epoch[14 of 15]: [Validate] CrossEntropyWithSoftmax = 1.79721110 * 83050; EvalClassificationError = 0.50168573 * 83050
MPI Rank 1: 02/03/2017 15:15:50: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.797211 (Epoch 14); EvalClassificationError = 0.501397 (Epoch 13)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:50: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 14: frames [286720..307200] (first utterance at frame 286720), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:50: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:51:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.78626990 * 10240; EvalClassificationError = 0.49990234 * 10240; time = 1.0389s; samplesPerSecond = 9856.3
MPI Rank 1: 02/03/2017 15:15:52:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81093423 * 10240; EvalClassificationError = 0.50566406 * 10240; time = 1.0316s; samplesPerSecond = 9926.4
MPI Rank 1: 02/03/2017 15:15:52: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.79860207 * 20480; EvalClassificationError = 0.50278320 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-005; epochTime=2.07975s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:15:55: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.79156270 * 83050; perplexity = 5.99881948; EvalClassificationError = 0.50039735 * 83050
MPI Rank 1: 02/03/2017 15:15:55: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.79156270 * 83050; EvalClassificationError = 0.50039735 * 83050
MPI Rank 1: 02/03/2017 15:15:55: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.791563 (Epoch 15); EvalClassificationError = 0.500397 (Epoch 15)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:56: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:56: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 2 D:\source\CNTK_exp_private\0\x64\release\cntk.exe configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu DeviceId=-1 timestamping=true makeMode=true numCPUThreads=4 shareNodeValueMatrices=true saveBestModelPerCriterion=true stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:15:56

D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  makeMode=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
Changed current directory to D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes on a single host (2 requested); we (0) are in (participating)
CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:15:56

D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  makeMode=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
Changed current directory to D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes on a single host (2 requested); we (1) are in (participating)
MPI Rank 0: 02/03/2017 15:15:56: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr_speechTrain.logrank0
MPI Rank 0: CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:15:56
MPI Rank 0: 
MPI Rank 0: D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  makeMode=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
MPI Rank 0: 02/03/2017 15:15:56: Using 4 CPU threads.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: ##############################################################################
MPI Rank 0: 02/03/2017 15:15:56: #                                                                            #
MPI Rank 0: 02/03/2017 15:15:56: # speechTrain command (train action)                                         #
MPI Rank 0: 02/03/2017 15:15:56: #                                                                            #
MPI Rank 0: 02/03/2017 15:15:56: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: 
MPI Rank 0: Starting from checkpoint. Loading network from 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.14'.
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 0: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...........................................................................feature set 0: 83050 frames in 300 out of 300 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 300 utterances grouped into 1 chunks, av. chunk size: 300.0 utterances, 83050.0 frames
MPI Rank 0: 02/03/2017 15:15:56: 
MPI Rank 0: Model has 25 nodes. Using CPU.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 02/03/2017 15:15:56: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:56: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 02/03/2017 15:15:56: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 0: 02/03/2017 15:15:56: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 0: 02/03/2017 15:15:56: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 0: 02/03/2017 15:15:56: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 0: 02/03/2017 15:15:56: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 0: 
MPI Rank 0: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 0: 02/03/2017 15:15:56: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:57: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 14: frames [286720..307200] (first utterance at frame 286720), data subset 0 of 2, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:15:57: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 0: 02/03/2017 15:15:58:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.78626990 * 10240; EvalClassificationError = 0.49990234 * 10240; time = 0.9577s; samplesPerSecond = 10692.3
MPI Rank 0: 02/03/2017 15:15:59:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81093423 * 10240; EvalClassificationError = 0.50566406 * 10240; time = 1.0191s; samplesPerSecond = 10048.3
MPI Rank 0: 02/03/2017 15:15:59: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.79860207 * 20480; EvalClassificationError = 0.50278320 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-005; epochTime=2.12575s
MPI Rank 0: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 0 of 2, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 02/03/2017 15:16:03: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.79156270 * 83050; perplexity = 5.99881948; EvalClassificationError = 0.50039735 * 83050
MPI Rank 0: 02/03/2017 15:16:03: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.79156270 * 83050; EvalClassificationError = 0.50039735 * 83050
MPI Rank 0: 02/03/2017 15:16:03: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.791563 (Epoch 15); EvalClassificationError = 0.500397 (Epoch 15)
MPI Rank 0: 02/03/2017 15:16:03: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn'
MPI Rank 0: 02/03/2017 15:16:03: Best epoch for criterion 'CrossEntropyWithSoftmax' is 15 and model C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn copied to C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn_CrossEntropyWithSoftmax
MPI Rank 0: 02/03/2017 15:16:03: Best epoch for criterion 'EvalClassificationError' is 15 and model C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn copied to C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn_EvalClassificationError
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:16:03: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 02/03/2017 15:16:03: __COMPLETED__
MPI Rank 1: 02/03/2017 15:15:56: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr_speechTrain.logrank1
MPI Rank 1: CNTK 2.0.beta6.0+ (gorand/criterion_ckp_1_master_public_1 af1f30, Jan  6 2017 16:36:39) on mdcs-gorand at 2017/02/03 15:15:56
MPI Rank 1: 
MPI Rank 1: D:\source\CNTK_exp_private\0\x64\release\cntk.exe  configFile=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion/cntkcv.cntk  currentDirectory=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  RunDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DataDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\DNN\SaveBestModelPerCriterion  OutputDir=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu  DeviceId=-1  timestamping=true  makeMode=true  numCPUThreads=4  shareNodeValueMatrices=true  saveBestModelPerCriterion=true  stderr=C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/stderr
MPI Rank 1: 02/03/2017 15:15:56: Using 4 CPU threads.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:56: ##############################################################################
MPI Rank 1: 02/03/2017 15:15:56: #                                                                            #
MPI Rank 1: 02/03/2017 15:15:56: # speechTrain command (train action)                                         #
MPI Rank 1: 02/03/2017 15:15:56: #                                                                            #
MPI Rank 1: 02/03/2017 15:15:56: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:56: 
MPI Rank 1: Starting from checkpoint. Loading network from 'C:\cygwin64\tmp\cntk-test-20170203161423.561595\Speech\DNN_SaveBestModelPerCriterion@release_cpu/models/cntkSpeech.dnn.14'.
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: reading script file glob_0000.cv.scp ... 300 entries
MPI Rank 1: total 132 state names in state list D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file D:\source\CNTK_exp_private\0\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...........................................................................feature set 0: 83050 frames in 300 out of 300 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 300 utterances grouped into 1 chunks, av. chunk size: 300.0 utterances, 83050.0 frames
MPI Rank 1: 02/03/2017 15:15:57: 
MPI Rank 1: Model has 25 nodes. Using CPU.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:57: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 02/03/2017 15:15:57: Evaluation criterion: EvalClassificationError = ClassificationError
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:57: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:57: 	Node 'B0' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 02/03/2017 15:15:57: 	Node 'B1' (LearnableParameter operation) : [512 x 1]
MPI Rank 1: 02/03/2017 15:15:57: 	Node 'B2' (LearnableParameter operation) : [132 x 1]
MPI Rank 1: 02/03/2017 15:15:57: 	Node 'W0' (LearnableParameter operation) : [512 x 363]
MPI Rank 1: 02/03/2017 15:15:57: 	Node 'W1' (LearnableParameter operation) : [512 x 512]
MPI Rank 1: 02/03/2017 15:15:57: 	Node 'W2' (LearnableParameter operation) : [132 x 512]
MPI Rank 1: 
MPI Rank 1: Initializing dataParallelSGD with FP64 aggregation.
MPI Rank 1: 02/03/2017 15:15:57: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:57: Starting Epoch 15: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 14: frames [286720..307200] (first utterance at frame 286720), data subset 1 of 2, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:15:57: Starting minibatch loop, DataParallelSGD training (myRank = 1, numNodes = 2, numGradientBits = 64), distributed reading is ENABLED.
MPI Rank 1: 02/03/2017 15:15:58:  Epoch[15 of 15]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.78626990 * 10240; EvalClassificationError = 0.49990234 * 10240; time = 1.0087s; samplesPerSecond = 10151.4
MPI Rank 1: 02/03/2017 15:15:59:  Epoch[15 of 15]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.81093423 * 10240; EvalClassificationError = 0.50566406 * 10240; time = 1.0190s; samplesPerSecond = 10049.0
MPI Rank 1: 02/03/2017 15:15:59: Finished Epoch[15 of 15]: [Training] CrossEntropyWithSoftmax = 1.79860207 * 20480; EvalClassificationError = 0.50278320 * 20480; totalSamplesSeen = 307200; learningRatePerSample = 9.7656251e-005; epochTime=2.12576s
MPI Rank 1: minibatchiterator: epoch 0: frames [0..83050] (first utterance at frame 0), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 02/03/2017 15:16:03: Final Results: Minibatch[1-83]: CrossEntropyWithSoftmax = 1.79156270 * 83050; perplexity = 5.99881948; EvalClassificationError = 0.50039735 * 83050
MPI Rank 1: 02/03/2017 15:16:03: Finished Epoch[15 of 15]: [Validate] CrossEntropyWithSoftmax = 1.79156270 * 83050; EvalClassificationError = 0.50039735 * 83050
MPI Rank 1: 02/03/2017 15:16:03: Best epoch per criterion so far: [Validate] CrossEntropyWithSoftmax = 1.791563 (Epoch 15); EvalClassificationError = 0.500397 (Epoch 15)
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:16:03: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 02/03/2017 15:16:03: __COMPLETED__